{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Review Helpfulness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction using Traditional ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all the necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'corpus'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-8f8e5d71f82f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTfidfTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'corpus'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "import string\n",
    "from nltk.corpus import corpus\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.layers import Embedding\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import load_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0345329139</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>5</td>\n",
       "      <td>This book is definitely a &amp;quot;must read.&amp;quo...</td>\n",
       "      <td>10 3, 2001</td>\n",
       "      <td>A2UNA438B0FRA8</td>\n",
       "      <td>J. Belfield</td>\n",
       "      <td>HILARIOUS!!!</td>\n",
       "      <td>1002067200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1419705644</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a really cool book for any adventure t...</td>\n",
       "      <td>03 20, 2014</td>\n",
       "      <td>A3ZV5ORJ94H2W</td>\n",
       "      <td>Cherish Woodring \"Cherry\"</td>\n",
       "      <td>awesome!</td>\n",
       "      <td>1395273600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0062257242</td>\n",
       "      <td>[7, 8]</td>\n",
       "      <td>4</td>\n",
       "      <td>I originally got this book because I wanted to...</td>\n",
       "      <td>04 1, 2014</td>\n",
       "      <td>A1UWPSFAJKKAW0</td>\n",
       "      <td>Mrs. Baumann</td>\n",
       "      <td>A fast-paced horror novel, but too scary for m...</td>\n",
       "      <td>1396310400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0778316084</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>3</td>\n",
       "      <td>This was my second least favorite of the Sulli...</td>\n",
       "      <td>04 3, 2013</td>\n",
       "      <td>AQRTK4Q9CCOVE</td>\n",
       "      <td>Renee M</td>\n",
       "      <td>Ok read</td>\n",
       "      <td>1364947200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00HTCC26C</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>3</td>\n",
       "      <td>I choose this book because I like the show, bu...</td>\n",
       "      <td>05 15, 2014</td>\n",
       "      <td>A2TCOVTJG32S6L</td>\n",
       "      <td>melonie</td>\n",
       "      <td>Short but pretty good</td>\n",
       "      <td>1400112000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin helpful  overall  \\\n",
       "0  0345329139  [1, 1]        5   \n",
       "1  1419705644  [0, 0]        5   \n",
       "2  0062257242  [7, 8]        4   \n",
       "3  0778316084  [0, 0]        3   \n",
       "4  B00HTCC26C  [0, 0]        3   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  This book is definitely a &quot;must read.&quo...   10 3, 2001   \n",
       "1  This is a really cool book for any adventure t...  03 20, 2014   \n",
       "2  I originally got this book because I wanted to...   04 1, 2014   \n",
       "3  This was my second least favorite of the Sulli...   04 3, 2013   \n",
       "4  I choose this book because I like the show, bu...  05 15, 2014   \n",
       "\n",
       "       reviewerID               reviewerName  \\\n",
       "0  A2UNA438B0FRA8                J. Belfield   \n",
       "1   A3ZV5ORJ94H2W  Cherish Woodring \"Cherry\"   \n",
       "2  A1UWPSFAJKKAW0               Mrs. Baumann   \n",
       "3   AQRTK4Q9CCOVE                    Renee M   \n",
       "4  A2TCOVTJG32S6L                    melonie   \n",
       "\n",
       "                                             summary  unixReviewTime  \n",
       "0                                       HILARIOUS!!!      1002067200  \n",
       "1                                           awesome!      1395273600  \n",
       "2  A fast-paced horror novel, but too scary for m...      1396310400  \n",
       "3                                            Ok read      1364947200  \n",
       "4                              Short but pretty good      1400112000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the dataset from the zip file\n",
    "df = pd.read_json('./data/sample_dataset.json', lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column-0 - asin\n",
      "Column-1 - helpful\n",
      "Column-2 - overall\n",
      "Column-3 - reviewText\n",
      "Column-4 - reviewTime\n",
      "Column-5 - reviewerID\n",
      "Column-6 - reviewerName\n",
      "Column-7 - summary\n",
      "Column-8 - unixReviewTime\n",
      "Shape - (50000, 9)\n"
     ]
    }
   ],
   "source": [
    "# Summary of the Dataset\n",
    "for index, column in enumerate(df.columns):\n",
    "    print('Column-{} - {}'.format(index, column))\n",
    "print('Shape - {}'.format(df.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the helpfulness Ratio\n",
    "def find_helpful_ratio(helpful_list):\n",
    "    if helpful_list[1] > 0:\n",
    "        return 1 if helpful_list[0]/helpful_list[1] >=0.5 else 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>helpfulness_raatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0345329139</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>5</td>\n",
       "      <td>This book is definitely a &amp;quot;must read.&amp;quo...</td>\n",
       "      <td>10 3, 2001</td>\n",
       "      <td>A2UNA438B0FRA8</td>\n",
       "      <td>J. Belfield</td>\n",
       "      <td>HILARIOUS!!!</td>\n",
       "      <td>1002067200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1419705644</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a really cool book for any adventure t...</td>\n",
       "      <td>03 20, 2014</td>\n",
       "      <td>A3ZV5ORJ94H2W</td>\n",
       "      <td>Cherish Woodring \"Cherry\"</td>\n",
       "      <td>awesome!</td>\n",
       "      <td>1395273600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0062257242</td>\n",
       "      <td>[7, 8]</td>\n",
       "      <td>4</td>\n",
       "      <td>I originally got this book because I wanted to...</td>\n",
       "      <td>04 1, 2014</td>\n",
       "      <td>A1UWPSFAJKKAW0</td>\n",
       "      <td>Mrs. Baumann</td>\n",
       "      <td>A fast-paced horror novel, but too scary for m...</td>\n",
       "      <td>1396310400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0778316084</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>3</td>\n",
       "      <td>This was my second least favorite of the Sulli...</td>\n",
       "      <td>04 3, 2013</td>\n",
       "      <td>AQRTK4Q9CCOVE</td>\n",
       "      <td>Renee M</td>\n",
       "      <td>Ok read</td>\n",
       "      <td>1364947200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00HTCC26C</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>3</td>\n",
       "      <td>I choose this book because I like the show, bu...</td>\n",
       "      <td>05 15, 2014</td>\n",
       "      <td>A2TCOVTJG32S6L</td>\n",
       "      <td>melonie</td>\n",
       "      <td>Short but pretty good</td>\n",
       "      <td>1400112000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin helpful  overall  \\\n",
       "0  0345329139  [1, 1]        5   \n",
       "1  1419705644  [0, 0]        5   \n",
       "2  0062257242  [7, 8]        4   \n",
       "3  0778316084  [0, 0]        3   \n",
       "4  B00HTCC26C  [0, 0]        3   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  This book is definitely a &quot;must read.&quo...   10 3, 2001   \n",
       "1  This is a really cool book for any adventure t...  03 20, 2014   \n",
       "2  I originally got this book because I wanted to...   04 1, 2014   \n",
       "3  This was my second least favorite of the Sulli...   04 3, 2013   \n",
       "4  I choose this book because I like the show, bu...  05 15, 2014   \n",
       "\n",
       "       reviewerID               reviewerName  \\\n",
       "0  A2UNA438B0FRA8                J. Belfield   \n",
       "1   A3ZV5ORJ94H2W  Cherish Woodring \"Cherry\"   \n",
       "2  A1UWPSFAJKKAW0               Mrs. Baumann   \n",
       "3   AQRTK4Q9CCOVE                    Renee M   \n",
       "4  A2TCOVTJG32S6L                    melonie   \n",
       "\n",
       "                                             summary  unixReviewTime  \\\n",
       "0                                       HILARIOUS!!!      1002067200   \n",
       "1                                           awesome!      1395273600   \n",
       "2  A fast-paced horror novel, but too scary for m...      1396310400   \n",
       "3                                            Ok read      1364947200   \n",
       "4                              Short but pretty good      1400112000   \n",
       "\n",
       "   helpfulness_raatio  \n",
       "0                   1  \n",
       "1                   0  \n",
       "2                   1  \n",
       "3                   0  \n",
       "4                   0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['helpfulness_raatio'] = df['helpful'].apply(func=find_helpful_ratio)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f99ae9a4550>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEICAYAAAC0+DhzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAF11JREFUeJzt3X+0XWV95/H3p0QUAQWl3iJEgzXOmEqLmAG6nJlG6cKAHaPWYWAhBMsYqzBTp2lr2pm1oFKqtAtdC6vWOGaAFgX8SSo4NEVu1bZBojL8ciwRgyQiqOFXZKoGv/PH2aGnee7NPbn35p7cm/drrbPuPs9+9nOe7004n+xn73NIVSFJUr+fGfYEJEl7H8NBktQwHCRJDcNBktQwHCRJDcNBktQwHDQ0STYl+dU9eVySf5Xk1iSPJfmvA/SvJC/c3TnNZkmel2Rbkv2GPRftPQwHzXW/B9xUVQdX1aXDnszeYOdwrapvV9VBVfXEMOelvYvhoLnu+cCdw57EdEkyb9hz0L7BcNCwHZPktiSPJLk6ydMAkvxatxz0cJK/T/KLYx2c5IIkn+iOfSzJV5P8Urfv88ArgD/rlk1elGQ0yX/uO/7sJF8aZ+zLkrw/yXXd2Dcn+fm+/f86ybokW5N8I8mpfftOSXJXd9yWJL/TtR+W5LNdXVuTfDHJLv877P6l/44ktwE/TDIvyaok3+zGvyvJ6/r6/3ySzyf5QZLvJ7kyySHdvr8Angf8Vfc7+b0kC7rltHldn+cmWdvNb2OSN+/yT1BzkuGgYTsVWAocBfwicHaSlwJrgLcAzwY+BKxN8tRxxlgGfBx4FvBR4DNJnlJVrwS+CJzXLZv84yTmdxrwh8ChwEbgIoAkBwLrutd7TtfvA0kWdcd9BHhLVR0MvAT4fNe+EtgM/CwwAvwBMMh32JwOvBo4pKq2A98E/h3wzG5+f5nk8K5vgHcBzwVeDMwHLgCoqjOBbwP/ofud/MkYr3VVN8fnAm8A/jjJKweYo+YQw0HDdmlVfaeqtgJ/BRwDrAA+VFU3V9UTVXU58CPghHHG+EpVfaKqfgK8B3jaLvrurk9X1Ze7N+Qru/kB/Bqwqar+V1Vtr6qvAZ8E/mO3/yfAoiTPqKqHquqrfe2HA8+vqp9U1RdrsC84u7Sq7quq/wdQVR/vfm8/raqrgbuB47p9G6tqXVX9qKq+R+938iuDFJtkPvBy4B1V9U9VdSvwP4GzBjlec4fhoGH7bt/248BB9K4TrOyWXh5O8jC9f/0+d5wx7tuxUVU/5Z//1bun5kc3x+N3muMZwM91+38dOAW4N8nfJvnlrv1P6Z2B/HWSe5KsGnAe9/U/SXJW37Lbw/TOTg7r9o0kuapbznoU+Msd+wbwXGBrVT3W13YvcMSAx2uOMBy0N7oPuKiqDul7PL2qPjZO//k7Nrr1+yOB74zT94fA0/ue/9w4/QaZ49/uNMeDquqtAFV1S1Uto7fk9Bngmq79sapaWVUvAF4D/HaSEwd4vSfPLpI8H/gwcB7w7Ko6BLiD3nISwB93/Y+uqmcAb+zb9y/GGsN3gGclObiv7XnAlgHmqDnEcNDe6MPAbyY5Pj0HJnn1Tm9Y/V6W5PXdBdW301uCWj9O31uB1yd5evd5hnMmOcfPAi9KcmaSp3SPf5PkxUn2T3JGkmd2S12PAj+FJy+0vzBJgEeAJ3bs2w0H0nuD/1435pvonTnscDCwDXgkyRHA7+50/APAC8YauKruA/4eeFeSp3U3ApxD7+xD+xDDQXudqtoAvBn4M+AhesswZ+/ikGuB/9T1PRN4ffemPJb3Aj+m9wZ5Ob3rCJOZ42PASfQuRH+H3vLTxcCOi+ZnApu6ZZ3fpLfkBLAQ+Bt6b97/AHygqm7azde+C7ikO/4B4Gjg7/q6/CFwLL3wuQ741E5DvAv4H92S1O+M8RKnAwu6uj4NnF9Vf7M7c9TsF/9nP5rNklwAvLCq3jjsuUhziWcOkqSGn7aUhizJ84C7xtm9qKq+PZPzkcBlJUnSGFxWkiQ1Zu2y0mGHHVYLFiyY1LE//OEPOfDAA6d3Qns5a9437Gs172v1wtRr/spXvvL9qvrZifrN2nBYsGABGzZsmNSxo6OjLFmyZHontJez5n3DvlbzvlYvTL3mJPcO0s9lJUlSw3CQJDUMB0lSw3CQJDUMB0lSw3CQJDUMB0lSw3CQJDUMB0lSY9Z+Qnoqbt/yCGevuq5p3/TuVw9hNpK09/HMQZLUMBwkSQ3DQZLUMBwkSQ3DQZLUMBwkSQ3DQZLUMBwkSQ3DQZLUMBwkSQ3DQZLUMBwkSQ3DQZLUMBwkSQ3DQZLUMBwkSQ3DQZLUMBwkSQ3DQZLUMBwkSY0JwyHJ/CQ3JbkryZ1JfqtrvyDJliS3do9T+o75/SQbk3wjyav62pd2bRuTrOprPyrJzV371Un2n+5CJUmDG+TMYTuwsqoWAScA5yZZ1O17b1Ud0z2uB+j2nQb8ArAU+ECS/ZLsB7wfOBlYBJzeN87F3VgvBB4Czpmm+iRJkzBhOFTV/VX11W77MeDrwBG7OGQZcFVV/aiqvgVsBI7rHhur6p6q+jFwFbAsSYBXAp/ojr8ceO1kC5IkTd283emcZAHwUuBm4OXAeUnOAjbQO7t4iF5wrO87bDP/HCb37dR+PPBs4OGq2j5G/51ffwWwAmBkZITR0dHdmf6TRg6AlUdvb9onO95ssG3btjld31isee7b1+qFmat54HBIchDwSeDtVfVokg8CFwLV/bwE+I09MstOVa0GVgMsXry4lixZMqlx3nfltVxye1v6pjMmN95sMDo6ymR/X7OVNc99+1q9MHM1DxQOSZ5CLxiurKpPAVTVA337Pwx8tnu6BZjfd/iRXRvjtP8AOCTJvO7sob+/JGkIBrlbKcBHgK9X1Xv62g/v6/Y64I5uey1wWpKnJjkKWAh8GbgFWNjdmbQ/vYvWa6uqgJuAN3THLweunVpZkqSpGOTM4eXAmcDtSW7t2v6A3t1Gx9BbVtoEvAWgqu5Mcg1wF707nc6tqicAkpwH3ADsB6ypqju78d4BXJXkj4Cv0QsjSdKQTBgOVfUlIGPsun4Xx1wEXDRG+/VjHVdV99C7m0mStBfwE9KSpIbhIElqGA6SpIbhIElqGA6SpIbhIElqGA6SpIbhIElqGA6SpIbhIElqGA6SpIbhIElqGA6SpIbhIElqGA6SpIbhIElqGA6SpIbhIElqGA6SpMaE/w9pSdLMW7DqujHbL1t64Iy8vmcOkqSG4SBJahgOkqSG4SBJahgOkqSG4SBJahgOkqSG4SBJakwYDknmJ7kpyV1J7kzyW137s5KsS3J39/PQrj1JLk2yMcltSY7tG2t51//uJMv72l+W5PbumEuTZE8UK0kazCBnDtuBlVW1CDgBODfJImAVcGNVLQRu7J4DnAws7B4rgA9CL0yA84HjgeOA83cEStfnzX3HLZ16aZKkyZowHKrq/qr6arf9GPB14AhgGXB51+1y4LXd9jLgiupZDxyS5HDgVcC6qtpaVQ8B64Cl3b5nVNX6qirgir6xJElDsFvfrZRkAfBS4GZgpKru73Z9Fxjpto8A7us7bHPXtqv2zWO0j/X6K+idjTAyMsLo6OjuTP9JIwfAyqO3N+2THW822LZt25yubyzWPPfN5XrHeo+Cmat54HBIchDwSeDtVfVo/2WBqqoktQfm9y9U1WpgNcDixYtryZIlkxrnfVdeyyW3t6VvOmNy480Go6OjTPb3NVtZ89w3l+s9exdfvDcTNQ90t1KSp9ALhiur6lNd8wPdkhDdzwe79i3A/L7Dj+zadtV+5BjtkqQhGeRupQAfAb5eVe/p27UW2HHH0XLg2r72s7q7lk4AHumWn24ATkpyaHch+iTghm7fo0lO6F7rrL6xJElDMMiy0suBM4Hbk9zatf0B8G7gmiTnAPcCp3b7rgdOATYCjwNvAqiqrUkuBG7p+r2zqrZ2228DLgMOAD7XPSRJQzJhOFTVl4DxPndw4hj9Czh3nLHWAGvGaN8AvGSiuUiSZoafkJYkNQwHSVLDcJAkNQwHSVLDcJAkNQwHSVLDcJAkNQwHSVLDcJAkNQwHSVLDcJAkNQwHSVLDcJAkNQwHSVLDcJAkNQwHSVLDcJAkNQwHSVLDcJAkNQwHSVLDcJAkNQwHSVLDcJAkNQwHSVLDcJAkNQwHSVLDcJAkNSYMhyRrkjyY5I6+tguSbElya/c4pW/f7yfZmOQbSV7V1760a9uYZFVf+1FJbu7ar06y/3QWKEnafYOcOVwGLB2j/b1VdUz3uB4gySLgNOAXumM+kGS/JPsB7wdOBhYBp3d9AS7uxnoh8BBwzlQKkiRN3YThUFVfALYOON4y4Kqq+lFVfQvYCBzXPTZW1T1V9WPgKmBZkgCvBD7RHX858NrdrEGSNM3mTeHY85KcBWwAVlbVQ8ARwPq+Ppu7NoD7dmo/Hng28HBVbR+jfyPJCmAFwMjICKOjo5Oa+MgBsPLo7U37ZMebDbZt2zan6xuLNc99c7nesd6jYOZqnmw4fBC4EKju5yXAb0zXpMZTVauB1QCLFy+uJUuWTGqc9115LZfc3pa+6YzJjTcbjI6OMtnf12xlzXPfXK737FXXjdl+2dIDZ6TmSYVDVT2wYzvJh4HPdk+3APP7uh7ZtTFO+w+AQ5LM684e+vtLkoZkUreyJjm87+nrgB13Mq0FTkvy1CRHAQuBLwO3AAu7O5P2p3fRem1VFXAT8Ibu+OXAtZOZkyRp+kx45pDkY8AS4LAkm4HzgSVJjqG3rLQJeAtAVd2Z5BrgLmA7cG5VPdGNcx5wA7AfsKaq7uxe4h3AVUn+CPga8JFpq06SNCkThkNVnT5G87hv4FV1EXDRGO3XA9eP0X4PvbuZJEl7CT8hLUlqGA6SpIbhIElqGA6SpIbhIElqGA6SpIbhIElqGA6SpIbhIElqGA6SpIbhIElqGA6SpIbhIElqGA6SpIbhIElqGA6SpIbhIElqGA6SpIbhIElqGA6SpIbhIElqGA6SpIbhIElqGA6SpIbhIElqGA6SpIbhIElqGA6SpMaE4ZBkTZIHk9zR1/asJOuS3N39PLRrT5JLk2xMcluSY/uOWd71vzvJ8r72lyW5vTvm0iSZ7iIlSbtnkDOHy4ClO7WtAm6sqoXAjd1zgJOBhd1jBfBB6IUJcD5wPHAccP6OQOn6vLnvuJ1fS5I0wyYMh6r6ArB1p+ZlwOXd9uXAa/var6ie9cAhSQ4HXgWsq6qtVfUQsA5Y2u17RlWtr6oCrugbS5I0JPMmedxIVd3fbX8XGOm2jwDu6+u3uWvbVfvmMdrHlGQFvTMSRkZGGB0dndzkD4CVR29v2ic73mywbdu2OV3fWKx57pvL9Y71HgUzV/Nkw+FJVVVJajomM8BrrQZWAyxevLiWLFkyqXHed+W1XHJ7W/qmMyY33mwwOjrKZH9fs5U1z31zud6zV103ZvtlSw+ckZone7fSA92SEN3PB7v2LcD8vn5Hdm27aj9yjHZJ0hBNNhzWAjvuOFoOXNvXflZ319IJwCPd8tMNwElJDu0uRJ8E3NDtezTJCd1dSmf1jSVJGpIJl5WSfAxYAhyWZDO9u47eDVyT5BzgXuDUrvv1wCnARuBx4E0AVbU1yYXALV2/d1bVjovcb6N3R9QBwOe6hyRpiCYMh6o6fZxdJ47Rt4BzxxlnDbBmjPYNwEsmmockaeb4CWlJUsNwkCQ1DAdJUsNwkCQ1DAdJUsNwkCQ1DAdJUsNwkCQ1DAdJUsNwkCQ1DAdJUsNwkCQ1DAdJUsNwkCQ1DAdJUsNwkCQ1DAdJUsNwkCQ1DAdJUsNwkCQ1DAdJUsNwkCQ1DAdJUsNwkCQ1DAdJUsNwkCQ1DAdJUmNK4ZBkU5Lbk9yaZEPX9qwk65Lc3f08tGtPkkuTbExyW5Jj+8ZZ3vW/O8nyqZUkSZqq6ThzeEVVHVNVi7vnq4Abq2ohcGP3HOBkYGH3WAF8EHphApwPHA8cB5y/I1AkScOxJ5aVlgGXd9uXA6/ta7+ietYDhyQ5HHgVsK6qtlbVQ8A6YOkemJckaUDzpnh8AX+dpIAPVdVqYKSq7u/2fxcY6baPAO7rO3Zz1zZeeyPJCnpnHYyMjDA6OjqpSY8cACuP3t60T3a82WDbtm1zur6xWPPcN5frHes9Cmau5qmGw7+tqi1JngOsS/J/+3dWVXXBMS268FkNsHjx4lqyZMmkxnnflddyye1t6ZvOmNx4s8Ho6CiT/X3NVtY8983les9edd2Y7ZctPXBGap7SslJVbel+Pgh8mt41gwe65SK6nw923bcA8/sOP7JrG69dkjQkkw6HJAcmOXjHNnAScAewFthxx9Fy4Npuey1wVnfX0gnAI93y0w3ASUkO7S5En9S1SZKGZCrLSiPAp5PsGOejVfW/k9wCXJPkHOBe4NSu//XAKcBG4HHgTQBVtTXJhcAtXb93VtXWKcxLkjRFkw6HqroH+KUx2n8AnDhGewHnjjPWGmDNZOciSZpefkJaktQwHCRJDcNBktQwHCRJDcNBktQwHCRJDcNBktQwHCRJDcNBktQwHCRJDcNBktQwHCRJDcNBktQwHCRJDcNBktQwHCRJDcNBktQwHCRJDcNBktQwHCRJDcNBktQwHCRJDcNBktQwHCRJDcNBktQwHCRJDcNBktQwHCRJjb0mHJIsTfKNJBuTrBr2fCRpX7ZXhEOS/YD3AycDi4DTkywa7qwkad+1V4QDcBywsaruqaofA1cBy4Y8J0naZ80b9gQ6RwD39T3fDBy/c6ckK4AV3dNtSb4xydc7DPh+M/7Fkxxtdhiz5jnOmue+fa1eXnHxlGt+/iCd9pZwGEhVrQZWT3WcJBuqavE0TGnWsOZ9w75W875WL8xczXvLstIWYH7f8yO7NknSEOwt4XALsDDJUUn2B04D1g55TpK0z9orlpWqanuS84AbgP2ANVV15x58ySkvTc1C1rxv2Ndq3tfqhRmqOVU1E68jSZpF9pZlJUnSXsRwkCQ15nQ4TPSVHEmemuTqbv/NSRbM/CynzwD1/naSu5LcluTGJAPd77w3G/RrV5L8epJKMutvexyk5iSndn/Wdyb56EzPcboN8Hf7eUluSvK17u/3KcOY53RJsibJg0nuGGd/klza/T5uS3LstE+iqubkg96F7W8CLwD2B/4PsGinPm8D/rzbPg24etjz3sP1vgJ4erf91tlc76A1d/0OBr4ArAcWD3veM/DnvBD4GnBo9/w5w573DNS8Gnhrt70I2DTseU+x5n8PHAvcMc7+U4DPAQFOAG6e7jnM5TOHQb6SYxlwebf9CeDEJJnBOU6nCeutqpuq6vHu6Xp6nyeZzQb92pULgYuBf5rJye0hg9T8ZuD9VfUQQFU9OMNznG6D1FzAM7rtZwLfmcH5Tbuq+gKwdRddlgFXVM964JAkh0/nHOZyOIz1lRxHjNenqrYDjwDPnpHZTb9B6u13Dr1/ecxmE9bcnW7Pr6rrZnJie9Agf84vAl6U5O+SrE+ydMZmt2cMUvMFwBuTbAauB/7LzExtaHb3v/fdtld8zkEzK8kbgcXArwx7LntSkp8B3gOcPeSpzLR59JaWltA7O/xCkqOr6uGhzmrPOh24rKouSfLLwF8keUlV/XTYE5ut5vKZwyBfyfFknyTz6J2O/mBGZjf9BvoKkiS/Cvx34DVV9aMZmtueMlHNBwMvAUaTbKK3Nrt2ll+UHuTPeTOwtqp+UlXfAv6RXljMVoPUfA5wDUBV/QPwNHpfyjdX7fGvHJrL4TDIV3KsBZZ3228APl/d1Z5ZaMJ6k7wU+BC9YJjt69AwQc1V9UhVHVZVC6pqAb3rLK+pqg3Dme60GOTv9WfonTWQ5DB6y0z3zOQkp9kgNX8bOBEgyYvphcP3ZnSWM2stcFZ319IJwCNVdf90vsCcXVaqcb6SI8k7gQ1VtRb4CL3Tz430Lv6cNrwZT82A9f4pcBDw8e66+7er6jVDm/QUDVjznDJgzTcAJyW5C3gC+N2qmq1nxIPWvBL4cJL/Ru/i9Nmz+B96JPkYvYA/rLuOcj7wFICq+nN611VOATYCjwNvmvY5zOLfnyRpD5nLy0qSpEkyHCRJDcNBktQwHCRJDcNBktQwHCRJDcNBktT4/7H62OXULkiSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the distribution of the helpful ratio\n",
    "df.hist(column='helpfulness_raatio', bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "37500 37500\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into train and test\n",
    "reviews = df['reviewText']\n",
    "labels =  df['helpfulness_raatio']\n",
    "print(len(labels))\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(reviews, labels, test_size=0.25, random_state=1)\n",
    "print(len(X_train), len(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the pipeline\n",
    "\n",
    "def define_models():\n",
    "    model_svm = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf-svm', SGDClassifier()),])\n",
    "    parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False), 'clf-svm__alpha': (1e-2, 1e-3)}\n",
    "    return [(model_svm, parameters_svm)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model(model, X, Y, metric='accuracy', cv=5):\n",
    "    clf = GridSearchCV(estimator=model[0],param_grid=model[1], cv=cv, scoring=metric)\n",
    "    clf.fit(X, Y)\n",
    "    best_score = clf.best_score_\n",
    "    best_model = clf\n",
    "    return (best_model, best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_models_and_parameters():\n",
    "    final_models = []\n",
    "    models = define_models()\n",
    "    for i in range(0,len(models)):\n",
    "        best_model_and_score = tune_model(models[i], X_train, Y_train)\n",
    "    final_models.append(best_model_and_score)\n",
    "    final_list=sorted(final_models, key=lambda score: score[1], reverse=True)\n",
    "    return final_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "models_list = get_best_models_and_parameters()\n",
    "model = models_list[0][0]\n",
    "preds = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5097 2023]\n",
      " [2303 3077]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "report = confusion_matrix(Y_test, preds)\n",
    "labels = ['helpful', 'not helpful']\n",
    "print(report)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(report)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6439019360093563\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.72      0.70      7120\n",
      "           1       0.60      0.57      0.59      5380\n",
      "\n",
      "   micro avg       0.65      0.65      0.65     12500\n",
      "   macro avg       0.65      0.64      0.64     12500\n",
      "weighted avg       0.65      0.65      0.65     12500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {}'.format(balanced_accuracy_score(Y_test, preds)))\n",
    "cls_report = classification_report(Y_test, preds)\n",
    "print('Classification report')\n",
    "print(cls_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction using Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vectors(glove_file_name):\n",
    "    with open(glove_file_name, 'r') as f:\n",
    "        words = set()\n",
    "        word_to_vector_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            current_word = line[0]\n",
    "            words.add(current_word)\n",
    "            word_to_vector_map[current_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for word in sorted(words):\n",
    "            words_to_index[word] = i\n",
    "            index_to_words[i] = word\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vector_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading word embeding\n",
    " words_to_index, index_to_words, word_to_vector_map = read_glove_vectors('./word_embeding/glove.6B/glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(u, v):\n",
    "    \"\"\"\n",
    "    Cosine similarity reflects the degree of similariy between u and v\n",
    "        \n",
    "    \"\"\"\n",
    "    distance = 0.0\n",
    "    dot = np.dot(u, v)\n",
    "    l2_norm_u = np.sqrt(np.sum(u**2))\n",
    "    l2_norm_v = np.sqrt(np.sum(v**2))\n",
    "    cosine_similarity = dot/(l2_norm_u * l2_norm_v)\n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:8: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pregnant\n"
     ]
    }
   ],
   "source": [
    "#Sample word analogy using glove word embeding\n",
    "father = word_to_vector_map.get('father')\n",
    "mother = word_to_vector_map.get('mother')\n",
    "son = word_to_vector_map.get('husband')\n",
    "max_cosine_similarity = -1000\n",
    "best_word = None\n",
    "for word in word_to_vector_map.keys():\n",
    "    if word in (father, mother, son):\n",
    "        continue\n",
    "    cosine_sim = cosine_similarity(np.subtract(mother, father), np.subtract(word_to_vector_map.get(word), son))\n",
    "    if cosine_sim > max_cosine_similarity:\n",
    "        max_cosine_similarity = cosine_sim\n",
    "        best_word = word\n",
    "print(best_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting sentence to Indices\n",
    "def convert_sentence_to_indices(X, word_to_index, max_len):\n",
    "    \"\"\"\n",
    "    Convert the raw sentece into the its indices\n",
    "    \"\"\"\n",
    "    X = X.reset_index(drop=True)\n",
    "    m = X.shape[0]\n",
    "    indices = np.zeros((m, max_len))\n",
    "    for i in range(m):\n",
    "        words = X[i].lower().split()\n",
    "        words_without_stopwords = [for word in words ]\n",
    "        j = 0\n",
    "        for w in words:\n",
    "            vector = word_to_index.get(w)\n",
    "            if vector is not None:\n",
    "                indices[i,j] = word_to_index.get(w)\n",
    "                j = j + 1\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Embeding matrix\n",
    "def trained_embedding_layer(word_to_vector_map, word_to_index):\n",
    "    vocab_len = len(word_to_index) + 1\n",
    "    emb_dim = word_to_vector_map.get('king').shape[0]\n",
    "    embeding_matrix = np.zeros((vocab_len, emb_dim))\n",
    "    \n",
    "    for word, index in word_to_index.items():\n",
    "        embeding_matrix[index, :] = word_to_vector_map.get(word)\n",
    "        \n",
    "    layer = Embedding(vocab_len, emb_dim, trainable=False)\n",
    "    layer.build((None,))\n",
    "    layer.set_weights([embeding_matrix])\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_to_index():\n",
    "    tokonizer = Tokenizer(num_words=10000)\n",
    "    total_reviews = reviews.values\n",
    "    tokonizer.fit_on_texts(total_reviews)\n",
    "    encoded_docs = tokonizer.texts_to_sequences(total_reviews)\n",
    "    #max_length = max([len(s.split()) for s in total_reviews])\n",
    "    vocab_size = len(tokonizer.word_index) + 1\n",
    "    word_index = tokonizer.word_index\n",
    "    return vocab_size, word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Helpfulness prediction model\n",
    "def helpfulness_model(input_shape, word_to_vector_map, word_index):\n",
    "    # Define sentence indices as the input of the graph.\n",
    "    sentence_indices = Input(input_shape, dtype='int32')\n",
    "    # Create the embedding layer pretrained with GloVe Vectors (â‰ˆ1 line)\n",
    "    embedding_layer = trained_embedding_layer(word_to_vector_map, word_index)\n",
    "    \n",
    "    # Propagate sentence_indices through your embedding layer.\n",
    "    embeddings = embedding_layer(sentence_indices)\n",
    "    \n",
    "    # Propogate the embedings via LSTM cell of 64 units\n",
    "    X = LSTM(64, return_sequences=True)(embeddings)\n",
    "    # Add dropout with a probability of 0.5\n",
    "    X = Dropout(rate=0.5)(X)\n",
    "    # Propogate vis 64 units LSTM layer\n",
    "    X = LSTM(64, return_sequences=False)(X)\n",
    "    # Add dropout with a probability of 0.5\n",
    "    X = Dropout(rate=0.5)(X)\n",
    "    # Dense layer with 5 units\n",
    "    X = Dense(1, activation='sigmoid')(X)\n",
    "    \n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    model = Model(inputs=sentence_indices, outputs=X)\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_9 (Embedding)      (None, 200, 100)          40000100  \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 200, 64)           42240     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 200, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 40,075,429\n",
      "Trainable params: 75,329\n",
      "Non-trainable params: 40,000,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Compile the model\n",
    "vocab_size, word_index = get_words_to_index()\n",
    "model = helpfulness_model((200,), word_to_vector_map, word_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='model/helpfulness_prediction_model.hdf5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 200 is out of bounds for axis 1 with size 200",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-5010d748a1c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_sentence_to_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-70-2013857cda80>\u001b[0m in \u001b[0;36mconvert_sentence_to_indices\u001b[0;34m(X, word_to_index, max_len)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvector\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 200 is out of bounds for axis 1 with size 200"
     ]
    }
   ],
   "source": [
    "#Fit the model\n",
    "X_train_indices = convert_sentence_to_indices(X_train, word_index, 200)\n",
    "model.fit(X_train_indices, Y_train, epochs = 10, batch_size = 32, validation_split=0.2, callbacks=[checkpointer, early_stopping], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    I found this book to be very useful in learnin...\n",
      "1    For a light, genteel, congenial venture into t...\n",
      "2    I loved this book. One of the themes in the ne...\n",
      "3    In this second Grace Murphy novel, we get to s...\n",
      "4    This is definitely a page turner. Just when yo...\n",
      "Name: reviewText, dtype: object\n",
      "Accuracy: 0.6439019360093563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.72      0.70      7120\n",
      "           1       0.60      0.57      0.59      5380\n",
      "\n",
      "   micro avg       0.65      0.65      0.65     12500\n",
      "   macro avg       0.65      0.64      0.64     12500\n",
      "weighted avg       0.65      0.65      0.65     12500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test_indices = convert_sentence_to_indices(X_test, words_to_index, 100)\n",
    "pred = model.predict(X_test_indices)\n",
    "print('Accuracy: {}'.format(balanced_accuracy_score(Y_test, preds)))\n",
    "complete_repost = classification_report(Y_test, preds)\n",
    "print(complete_repost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Helpfulness prediction model\n",
    "def helpfulness_model_v2(input_shape):\n",
    "    # Define sentence indices as the input of the graph.\n",
    "    sentence_indices = Input(input_shape, dtype='int32')\n",
    "    # Create the embedding layer pretrained with GloVe Vectors (â‰ˆ1 line)\n",
    "    embedding_layer = trained_embedding_layer(word_to_vector_map, words_to_index)\n",
    "    \n",
    "    # Propagate sentence_indices through your embedding layer.\n",
    "    #embeddings = Embedding(vocab_size, 100)(sentence_indices)\n",
    "    embeddings = embedding_layer(sentence_indices)\n",
    "    # Propogate the embedings via LSTM cell of 64 units\n",
    "    X = LSTM(128, return_sequences=True)(embeddings)\n",
    "    # Add dropout with a probability of 0.5\n",
    "    X = Dropout(rate=0.5)(X)\n",
    "    # Propogate vis 64 units LSTM layer\n",
    "    X = LSTM(128, return_sequences=False)(X)\n",
    "    # Add dropout with a probability of 0.5\n",
    "    X = Dropout(rate=0.5)(X)\n",
    "    # Dense layer with 5 units\n",
    "    X = Dense(1, activation='sigmoid')(X)\n",
    "\n",
    "    \n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    model = Model(inputs=sentence_indices, outputs=X)\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'add' did not contain a loop with signature matching types dtype('<U90') dtype('<U90') dtype('<U90')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1504\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1505\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr_rep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0meval_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1506\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(op, op_str, a, b, use_numexpr, **eval_kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0meval_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b, **eval_kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't convert 'int' object to str implicitly",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36msafe_na_op\u001b[0;34m(lvalues, rvalues)\u001b[0m\n\u001b[1;32m   1528\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1530\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1506\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasked_arith_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mmasked_arith_op\u001b[0;34m(x, y, op)\u001b[0m\n\u001b[1;32m   1008\u001b[0m                 result[mask] = op(xrav[mask],\n\u001b[0;32m-> 1009\u001b[0;31m                                   com.values_from_object(yrav[mask]))\n\u001b[0m\u001b[1;32m   1010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't convert 'int' object to str implicitly",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-26e19afbdb43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Compile the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_words_to_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhelpfulness_model_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-63d58fd8d04d>\u001b[0m in \u001b[0;36mget_words_to_index\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_words_to_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtokonizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtotal_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtokonizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_reviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mencoded_docs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokonizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_reviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(left, right)\u001b[0m\n\u001b[1;32m   1581\u001b[0m             \u001b[0mrvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1583\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_na_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1584\u001b[0m         return construct_result(left, result,\n\u001b[1;32m   1585\u001b[0m                                 index=left.index, name=res_name, dtype=None)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36msafe_na_op\u001b[0;34m(lvalues, rvalues)\u001b[0m\n\u001b[1;32m   1531\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1532\u001b[0m                 return libalgos.arrmap_object(lvalues,\n\u001b[0;32m-> 1533\u001b[0;31m                                               lambda x: op(x, rvalues))\n\u001b[0m\u001b[1;32m   1534\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/algos.pyx\u001b[0m in \u001b[0;36mpandas._libs.algos.arrmap\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1531\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1532\u001b[0m                 return libalgos.arrmap_object(lvalues,\n\u001b[0;32m-> 1533\u001b[0;31m                                               lambda x: op(x, rvalues))\n\u001b[0m\u001b[1;32m   1534\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'add' did not contain a loop with signature matching types dtype('<U90') dtype('<U90') dtype('<U90')"
     ]
    }
   ],
   "source": [
    "#Compile the model\n",
    "vocab_size, max_length, word_index = get_words_to_index()\n",
    "model_2 = helpfulness_model_v2((max_length,))\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling the created model with loss function, optimizer and evaluation metrics. \n",
    "For this task we are using `binary_crossentropy` as loss function and `adam` as optimizer and `accuracy` as a evaluation metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoints for saving the best model and early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model using the train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    I do like. A good mystery. And I found this bo...\n",
      "1    Firts book I read from Coben. Interesting plot...\n",
      "2    Trace Rawlins has major trust issues. Issues t...\n",
      "3    If you're looking for a light cozy read, this ...\n",
      "4    If you have read any of her books you are neve...\n",
      "Name: reviewText, dtype: object\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_4 to have shape (3791,) but got array with shape (100,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-5e160254cd56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_train_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_sentence_to_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords_to_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_4 to have shape (3791,) but got array with shape (100,)"
     ]
    }
   ],
   "source": [
    "X_train_indices = convert_sentence_to_indices(X_train, words_to_index, 100)\n",
    "model_2.fit(X_train_indices, Y_train, epochs=10, batch_size=32, validation_split=0.2, shuffle=True, callbacks=[checkpointer, early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting model and the history of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(model_to_dot(model_2).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(model_2.history['acc'])\n",
    "plt.plot(model_2.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(model_2.history['loss'])\n",
    "plt.plot(model_2.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
